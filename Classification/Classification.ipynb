{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "15cVoWC8jFJDVi3tv2P2ck8bQdKQ7d0jf",
      "authorship_tag": "ABX9TyObt4o1qVYgmkAs4I2HofyK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeong1suk/CT_Classification_segmentation/blob/main/ImageClassification/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 흉부 X-ray 이미지로 정상/코로나 폐렴을 분류하는 Image Classification"
      ],
      "metadata": {
        "id": "Ljo3BnwSYkL4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 라이브러리 불러오기"
      ],
      "metadata": {
        "id": "UZy19xU5YsWb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVbnql1FYgHd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import copy\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import interact\n",
        "\n",
        "random_seed = 2000\n",
        "\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed(random_seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 이미지 파일경로 불러오기"
      ],
      "metadata": {
        "id": "9XRHtHXxZ7hZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_image_files(data_dir, sub_dir):\n",
        "    image_format = [\"jpeg\", \"jpg\", \"png\"]\n",
        "\n",
        "    image_files = []\n",
        "    images_dir = os.path.join(data_dir, sub_dir)\n",
        "    for file_path in os.listdir(images_dir):\n",
        "        if file_path.split(\".\")[-1] in image_format:\n",
        "            image_files.append(os.path.join(sub_dir, file_path))\n",
        "    return image_files"
      ],
      "metadata": {
        "id": "ZVIGEJt8Z5j3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/MyDrive/DATASET/Classification/train/\"\n",
        "\n",
        "normals_list = list_image_files(data_dir, \"Normal\")\n",
        "covids_list = list_image_files(data_dir, \"Covid\")\n",
        "pneumonias_list = list_image_files(data_dir, \"Viral Pneumonia\")"
      ],
      "metadata": {
        "id": "7RBChF7QaQns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(normals_list), len(covids_list), len(pneumonias_list))"
      ],
      "metadata": {
        "id": "leGvFY1DaXu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 이미지파일을 RGB 3차원 배열로 불러오기"
      ],
      "metadata": {
        "id": "fP8t7X-ta9nG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_RGB_image(data_dir, file_name):\n",
        "    image_file = os.path.join(data_dir, file_name)\n",
        "    image = cv2.imread(image_file)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    return image"
      ],
      "metadata": {
        "id": "UP3ErobNa8FZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 이미지데이터 확인하기"
      ],
      "metadata": {
        "id": "Mqsh4Bn8bLm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_num_files = min(len(normals_list), len(covids_list), len(pneumonias_list))\n",
        "\n",
        "@interact(index=(0, min_num_files-1))\n",
        "def show_samples(index=0):\n",
        "    normal_image = get_RGB_image(data_dir, normals_list[index])\n",
        "    covid_image = get_RGB_image(data_dir, covids_list[index])\n",
        "    pneumonia_image = get_RGB_image(data_dir, pneumonias_list[index])\n",
        "\n",
        "    plt.figure(figsize=(12,8))\n",
        "    plt.subplot(131)\n",
        "    plt.title(\"Normal\")\n",
        "    plt.imshow(normal_image)\n",
        "    plt.subplot(132)\n",
        "    plt.title(\"Covid\")\n",
        "    plt.imshow(covid_image)\n",
        "    plt.subplot(133)\n",
        "    plt.title(\"Viral Pneumonia\")\n",
        "    plt.imshow(pneumonia_image)\n",
        "    plt.tight_layout()"
      ],
      "metadata": {
        "id": "pNSxx9QZbKyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "~인덱스별로 하나씩 확인하려고 interact 쓴건데 계속 쌓이네??~"
      ],
      "metadata": {
        "id": "9FRUqS2lb4rK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 학습데이터셋 클래스 구축"
      ],
      "metadata": {
        "id": "ysPR9n9LciK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = \"/content/drive/MyDrive/DATASET/Classification/train/\"\n",
        "class_list = [\"Normal\", \"Covid\", \"Viral Pneumonia\"]"
      ],
      "metadata": {
        "id": "PJtZ-wOWbu4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Chest_dataset(Dataset):\n",
        "    def __init__(self, data_dir, transformer=None):\n",
        "        self.data_dir = data_dir\n",
        "        normals = list_image_files(data_dir, \"Normal\")\n",
        "        covids = list_image_files(data_dir, \"Covid\")\n",
        "        pneumonias = list_image_files(data_dir, \"Viral Pneumonia\")\n",
        "\n",
        "        self.files_path = normals + covids + pneumonias\n",
        "        self.transform = transformer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files_path)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_file = os.path.join(self.data_dir, self.files_path[index])\n",
        "        image = cv2.imread(image_file)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # target = class_list.index(self.files_path[index].split(os.sep)[-2])\n",
        "\n",
        "        target = class_list.index(self.files_path[index].split(os.sep)[0])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            target = torch.Tensor([target]).long()\n",
        "\n",
        "        return {\"image\":image, \"target\":target}"
      ],
      "metadata": {
        "id": "7VJIHOugdXTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normals = list_image_files(data_dir, \"Normal\")\n",
        "covids = list_image_files(data_dir, \"Covid\")\n",
        "pneumonias = list_image_files(data_dir, \"Viral Pneumonia\")\n",
        "files_path = normals + covids + pneumonias\n",
        "print(files_path)"
      ],
      "metadata": {
        "id": "jn2n8eNXe5SU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(files_path[200].split(os.sep)[0])"
      ],
      "metadata": {
        "id": "LlCRx761eySI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dset = Chest_dataset(train_data_dir)"
      ],
      "metadata": {
        "id": "x0mAT9_ifDmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 200\n",
        "plt.title(class_list[dset[index][\"target\"]])\n",
        "plt.imshow(dset[index][\"image\"])"
      ],
      "metadata": {
        "id": "lbIv7z0MfkE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. 데이터로더 구현하기"
      ],
      "metadata": {
        "id": "ddYEdb2Hf8KK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "2Sb7iiHZhKY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataloader(train_data_dir, val_data_dir):\n",
        "    dataloaders = {}\n",
        "    train_dset = Chest_dataset(train_data_dir, transformer)\n",
        "    dataloaders[\"train\"] = DataLoader(train_dset, batch_size=4, shuffle=True, drop_last=True)\n",
        "\n",
        "    val_dset = Chest_dataset(val_data_dir, transformer)\n",
        "    dataloaders[\"val\"] = DataLoader(val_dset, batch_size=1, shuffle=False, drop_last=False)\n",
        "    return dataloaders"
      ],
      "metadata": {
        "id": "q3t7SUf4f-ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = \"/content/drive/MyDrive/DATASET/Classification/train/\"\n",
        "val_data_dir = \"/content/drive/MyDrive/DATASET/Classification/test/\"\n",
        "dataloaders = build_dataloader(train_data_dir, val_data_dir)"
      ],
      "metadata": {
        "id": "1vcD_SYqgVlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataloaders)"
      ],
      "metadata": {
        "id": "mUJz_1Pthcjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, d in enumerate(dataloaders[\"train\"]):\n",
        "    if i == 0:\n",
        "        break"
      ],
      "metadata": {
        "id": "hZzjn7EkghXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d[\"target\"].shape"
      ],
      "metadata": {
        "id": "XGVuxdEIgyKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d[\"target\"].squeeze()"
      ],
      "metadata": {
        "id": "mRFpU7Rxg2dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. VGG19 모델 불러오기"
      ],
      "metadata": {
        "id": "Ru8v9BY_qh6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg19(pretrained=True)"
      ],
      "metadata": {
        "id": "e_LRLzK5hRgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3, 224, 224), batch_size=1, device=\"cpu\")"
      ],
      "metadata": {
        "id": "1Buyps75qmqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. 데이터에 맞게 Head 부분 변경하기"
      ],
      "metadata": {
        "id": "punijqcoqwbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(512, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.1),\n",
        "    nn.Linear(256, len(class_list)),\n",
        "    nn.Sigmoid()\n",
        ")"
      ],
      "metadata": {
        "id": "VafzWWZWqt2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vgg19_based_model(device=\"cpu\"):\n",
        "    device = torch.device(device)\n",
        "    model = models.vgg19(pretrained=True)\n",
        "    model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, len(class_list)),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "    model.to(device)\n",
        "    return model"
      ],
      "metadata": {
        "id": "LiYEQGfTq7IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_vgg19_based_model(device='cpu')"
      ],
      "metadata": {
        "id": "Yko9uarhrKqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "qDjx0MG2rN1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. 손실함수"
      ],
      "metadata": {
        "id": "IG7zJPlkrYCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.CrossEntropyLoss(reduction=\"mean\")"
      ],
      "metadata": {
        "id": "srSl9rdqrZl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Gradient 최적화 함수"
      ],
      "metadata": {
        "id": "qlVIOi0qrePj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "7teNPMUhrdfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. 모델 검증을 위한 Accuracy 생성하기"
      ],
      "metadata": {
        "id": "TLoVJQvbrlTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def get_accuracy(image, target, model):\n",
        "    batch_size = image.shape[0]\n",
        "    prediction = model(image)\n",
        "    _, pred_label = torch.max(prediction, dim=1)\n",
        "    accuracy = (pred_label == target).sum().item() / batch_size\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "3DDYRVt6rkyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. 모델 학습"
      ],
      "metadata": {
        "id": "EXR-4F0Ir2R5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "IL46-reYr1rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, batch in enumerate(dataloaders[\"train\"]):\n",
        "    print(batch[\"target\"].squeeze(dim=1).to(device))\n",
        "    break"
      ],
      "metadata": {
        "id": "cV3ARI_qur0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(dataloaders, model, optimizer, loss_func, device):\n",
        "    losses = {}\n",
        "    accuracies = {}\n",
        "\n",
        "    for phase in [\"train\", \"val\"]:\n",
        "        running_loss = 0.0\n",
        "        running_correct = 0\n",
        "\n",
        "        if phase == \"train\":\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "\n",
        "        for index, batch in enumerate(dataloaders[phase]):\n",
        "            image = batch[\"image\"].to(device)\n",
        "            target = batch[\"target\"].squeeze(dim=1).to(device)\n",
        "\n",
        "            with torch.set_grad_enabled(phase == \"train\"):\n",
        "                prediction = model(image)\n",
        "                loss = loss_func(prediction, target)\n",
        "\n",
        "                if phase == \"train\":\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            running_correct += get_accuracy(image, target, model)\n",
        "\n",
        "            if phase == \"train\":\n",
        "                if index % 10 == 0:\n",
        "                    print(f\"{index}/{len(dataloaders[phase])} - Running Loss : {loss.item()}\")\n",
        "\n",
        "        losses[phase] = running_loss / len(dataloaders[phase])\n",
        "        accuracies[phase] = running_correct / len(dataloaders[phase])\n",
        "\n",
        "    return losses, accuracies"
      ],
      "metadata": {
        "id": "Z-vzFtJFr5vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_best_model(model_state, model_name, save_dir=\"./trained_model\"):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    torch.save(model_state, os.path.join(save_dir, model_name))"
      ],
      "metadata": {
        "id": "EvGGWTCjsyIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. 모델 학습 수행하기"
      ],
      "metadata": {
        "id": "7AWZPexvs6g1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_data_dir = \"/content/drive/MyDrive/DATASET/Classification/train/\"\n",
        "val_data_dir = \"/content/drive/MyDrive/DATASET/Classification/test/\"\n",
        "\n",
        "dataloaders = build_dataloader(train_data_dir, val_data_dir)\n",
        "model = build_vgg19_based_model(device=device)\n",
        "loss_func = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "hhX-kwyHs5tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(dataloaders, model, optimizer, loss_function, device):\n",
        "    losses = {}\n",
        "    accuracies = {}\n",
        "\n",
        "    for phase in [\"train\", \"val\"]:\n",
        "        running_loss = 0.0\n",
        "        running_correct = 0.0 # 매번 트레인과 밸리데이션 페이지별로 accuracy도 누적시킴\n",
        "\n",
        "        if phase == \"train\":\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "\n",
        "        for index, batch in enumerate(dataloaders[phase]):\n",
        "            image = batch[\"image\"].to(device) # 첫번째 리턴값: 이미지\n",
        "            label = batch[\"target\"].squeeze(dim=1).to(device) # 두번째 리턴값: 클래스 아이디\n",
        "\n",
        "            with torch.set_grad_enabled(phase == \"train\"):\n",
        "                prediction = model(image)\n",
        "                loss = loss_func(prediction, label)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                if phase == \"train\":\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            running_correct += get_accuracy(image, label, model)\n",
        "\n",
        "            if phase == \"train\":\n",
        "                if index % 10 == 0:\n",
        "                    print(f\"{index}/{len(dataloaders['train'])} - Running loss: {loss.item()}\")\n",
        "\n",
        "        losses[phase] = running_loss / len(dataloaders[phase])\n",
        "        accuracies[phase] = running_correct / len(dataloaders[phase])\n",
        "\n",
        "    return losses, accuracies"
      ],
      "metadata": {
        "id": "xYNWKYnCvtUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "best_acc = 0.0\n",
        "train_loss, train_acc = [], []\n",
        "val_loss, val_acc = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    losses, accuracies = train_one_epoch(dataloaders, model, optimizer, loss_func, device)\n",
        "    train_loss.append(losses['train'])\n",
        "    train_acc.append(accuracies['train'])\n",
        "    val_loss.append(losses['val'])\n",
        "    val_acc.append(accuracies['val'])\n",
        "\n",
        "    print(f\"{epoch}/{num_epochs}-Tr loss:{losses['train']}, Val loss {losses['val']}\")\n",
        "    print(f\"{epoch}/{num_epochs}-Tr acc:{accuracies['train']}, Val acc {accuracies['val']}\")\n",
        "\n",
        "    if accuracies[\"val\"] > best_acc:\n",
        "        best_acc = accuracies['val']\n",
        "        torch.save(model.state_dict(), f\"model_{epoch}.pth\")"
      ],
      "metadata": {
        "id": "CA4dOF5ltQOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. 테스트 이미지를 통한 학습모델 분류 성능 검증하기"
      ],
      "metadata": {
        "id": "pp_uA5xeyE0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/MyDrive/DATASET/Classification/test/\"\n",
        "class_list = [\"Normal\", \"Covid\", \"Viral Pneumonia\"]\n",
        "\n",
        "test_normals_list = list_image_files(data_dir, \"Normal\")\n",
        "test_covids_list = list_image_files(data_dir, \"Covid\")\n",
        "test_pneumonias_list = list_image_files(data_dir, \"Viral Pneumonia\")"
      ],
      "metadata": {
        "id": "Kh-ggCyFv1sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image):\n",
        "    transformer = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    tensor_image = transformer(image) # (C, H, W)\n",
        "    tensor_image = tensor_image.unsqueeze(dim=0) # (B, C, H, W)\n",
        "    return tensor_image"
      ],
      "metadata": {
        "id": "ECb-Sj1myRlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def model_predict(image, model):\n",
        "    tensor_image = preprocess_image(image)\n",
        "    prediction = model(tensor_image)\n",
        "    _, pred_label = torch.max(prediction.detach().cpu(), dim=1) #(B, NUM_CLASSES)\n",
        "    pred_label = pred_label.squeeze(dim=0)\n",
        "    return pred_label.item() # 토치 변수가 가지고 있는 수치적인 값만을 가져옴"
      ],
      "metadata": {
        "id": "WtPhgjkPyS3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt = torch.load(\"/content/model_5.pth\")\n",
        "\n",
        "model = build_vgg19_based_model(device='cpu')\n",
        "model.load_state_dict(ckpt)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "onfTSplTyT_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_num_files = min(len(test_normals_list), len(test_covids_list), len(test_pneumonias_list))\n",
        "\n",
        "@interact(index=(0, min_num_files-1))\n",
        "def show_result(index=0):\n",
        "    normal_image = get_RGB_image(data_dir, test_normals_list[index])\n",
        "    covid_image = get_RGB_image(data_dir, test_covids_list[index])\n",
        "    pneumonia_image = get_RGB_image(data_dir, test_pneumonias_list[index])\n",
        "\n",
        "    pred_normal = model_predict(normal_image, model)\n",
        "    pred_covid = model_predict(covid_image, model)\n",
        "    pred_pneumonia = model_predict(pneumonia_image, model)\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.subplot(131)\n",
        "    plt.title(f\"Pred:{class_list[pred_normal]} | GT:Normal\")\n",
        "    plt.imshow(normal_image)\n",
        "\n",
        "    plt.subplot(132)\n",
        "    plt.title(f\"Pred:{class_list[pred_covid]} | GT:Covid\")\n",
        "    plt.imshow(covid_image)\n",
        "\n",
        "    plt.subplot(133)\n",
        "    plt.title(f\"Pred:{class_list[pred_pneumonia]} | GT:Viral Pneumonia\")\n",
        "    plt.imshow(pneumonia_image)"
      ],
      "metadata": {
        "id": "oTFhA5kCyd7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SxW7CF_qyeO6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}